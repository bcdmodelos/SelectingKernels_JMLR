{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, DotProduct, ExpSineSquared, Matern, RBF, RationalQuadratic, WhiteKernel\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations_with_repetition(kernels, operation):\n",
    "    combinations = []\n",
    "    for r in range(2, 5):\n",
    "        for comb in itertools.combinations_with_replacement(kernels, r):\n",
    "            combinations.append(f\" {operation} \".join(comb))\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations_with_repetition(kernels, operations):\n",
    "    permutations = []\n",
    "    for r in range(2, 5):\n",
    "        for perm in itertools.product(kernels, repeat=r):\n",
    "            for ops in itertools.product(operations, repeat=r-1):\n",
    "                expr = \"\"\n",
    "                for i in range(r-1):\n",
    "                    expr += f\"{perm[i]} {ops[i]} \"\n",
    "                expr += perm[-1]\n",
    "                permutations.append(expr)\n",
    "    return permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_sample(data, sample_size, n_clusters=10):\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data).toarray()\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    sampled_data = []\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_items = [data[i] for i in range(len(data)) if labels[i] == cluster]\n",
    "        sample_count = min(sample_size // n_clusters, len(cluster_items))\n",
    "        sampled_data += random.sample(cluster_items, sample_count) if cluster_items else []\n",
    "    \n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['ConstantKernel()', 'DotProduct()', 'ExpSineSquared()', 'Matern()', 'RBF()', 'RationalQuadratic()', 'WhiteKernel()']\n",
    "operations = ['*', '+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for op in operations:\n",
    "    combinations += generate_combinations_with_repetition(kernels, op)\n",
    "\n",
    "permutations = generate_permutations_with_repetition(kernels, operations)\n",
    "\n",
    "all_combinations = combinations + permutations + kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations_views = set()\n",
    "duplicates_views = set()\n",
    "\n",
    "for item in all_combinations:\n",
    "    if item in all_combinations_views:\n",
    "        duplicates_views.add(item) \n",
    "    else:\n",
    "        all_combinations_views.add(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to generate kernel performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = f\"data/input/your_file.csv\"\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "time = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total = np.array(df['Your_Column_Name'].values)\n",
    "data = data_total[:int(time)]\n",
    "data = data.reshape(-1, 1)\n",
    "\n",
    "CRdata = data/1000\n",
    "CRdata  = np.ravel(CRdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainL = len(CRdata) - 60\n",
    "t = np.linspace(1,len(CRdata),len(CRdata))\n",
    "t = t.reshape(len(t),1)\n",
    "t = np.atleast_2d(t)\n",
    "\n",
    "t_tr  = t[0:trainL]\n",
    "t_test = t[trainL:]\n",
    "\n",
    "CR_tr = CRdata[0:trainL]\n",
    "CR_test = CRdata[trainL:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics_to_performance(CR_tr, t_tr, CR_test, t_test, kernel_str):\n",
    "    t = np.append(t_tr, t_test).reshape(-1, 1)\n",
    "    CRdata = np.append(CR_tr, CR_test)\n",
    "\n",
    "    kernel = kernel_str\n",
    "\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=False)\n",
    "    model.fit(t_tr, CR_tr)\n",
    "    params = model.kernel_.get_params()\n",
    "\n",
    "    R2_tr = model.score(t_tr, CR_tr)\n",
    "    R2 = model.score(t, CRdata)\n",
    "    R2_test = model.score(t_test, CR_test)\n",
    "\n",
    "    CRpred_tr, sigma_tr = model.predict(t_tr, return_std=True)\n",
    "    CRpred_test, sigma_test = model.predict(t_test, return_std=True)\n",
    "    CRpred, sigma = model.predict(t, return_std=True)\n",
    "\n",
    "    learned_kernel = model.kernel_\n",
    "\n",
    "    mse = np.mean(((CRpred_tr-CR_tr)*1000)**2)\n",
    "    lml = model.log_marginal_likelihood_value_\n",
    "    std = np.sqrt(mse)\n",
    "\n",
    "    return kernel_str, learned_kernel, mse, lml, std, R2_tr, R2, R2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kernel(kernel_str):\n",
    "  try:\n",
    "    result = Metrics_to_performance(CR_tr, t_tr, CR_test, t_test, kernel_str)\n",
    "    return result\n",
    "  except Exception as e:\n",
    "    print(f\"Error evaluating kernel {kernel_str}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_data = [eval(k) for k in all_combinations_views]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_batches = len(kernels_data) // batch_size + 1\n",
    "kernels_metrics = []\n",
    "num_cores = -1\n",
    "\n",
    "for i in range(num_batches):\n",
    "  start_idx = i * batch_size\n",
    "  end_idx = min((i + 1) * batch_size, len(kernels_data))\n",
    "  kernels_batch = kernels_data[start_idx:end_idx]\n",
    "\n",
    "  kernels_metrics_batch = Parallel(n_jobs=num_cores)(delayed(evaluate_kernel)(kernel_str) for kernel_str in tqdm(kernels_batch, desc=f\"Evaluating batch {i+1}/{num_batches}\"))\n",
    "\n",
    "  kernels_metrics.extend(kernels_metrics_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate File with all kernel combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/samples/your_samples_file.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'w', newline='') as file_csv:\n",
    "    writer = csv.writer(file_csv)\n",
    "    writer.writerow(['kernel_str', 'learned_kernel', 'mse', 'lml', 'std', 'R2_tr', 'R2', 'R2_test'])\n",
    "    for row in kernels_metrics:\n",
    "        if row is not None:\n",
    "            formatted_row = [row[0], row[1], '{:.4f}'.format(row[2]), '{:.4f}'.format(row[3]), '{:.4f}'.format(row[4]), '{:.4f}'.format(row[5]), '{:.4f}'.format(row[6]), '{:.4f}'.format(row[7])]\n",
    "            writer.writerow(formatted_row)\n",
    "\n",
    "print(f\"Data saved in: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
